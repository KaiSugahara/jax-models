{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eebdef00-3805-40b3-bd81-ac8e735c9d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "# ライブラリ\n",
    "########################################\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import nn\n",
    "from jax.nn.initializers import glorot_normal, normal\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tqdm import trange as tqdm_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16eae367-7fb5-411b-a82e-08e88487c370",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "# ニューラルネットワーク（フィードフォワード）\n",
    "########################################\n",
    "\n",
    "@jax.jit\n",
    "def Linear(params, x):\n",
    "    return jnp.dot(x, params[\"W\"]) + params[\"b\"]\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def ANN(params, x):\n",
    "    y1 = Linear(params[\"linear1\"], x)\n",
    "    z1 = nn.relu(y1)\n",
    "    y2 = Linear(params[\"linear2\"], z1)\n",
    "    z2 = nn.softmax(y2)\n",
    "    return z2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61c0be3a-d8f6-4c1b-b80c-150aa955c4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "# 訓練\n",
    "########################################\n",
    "\n",
    "# クロスエントロピー誤差\n",
    "@jax.jit\n",
    "def cross_entropy_loss(params, X, y):\n",
    "    logits = ANN(params, X)\n",
    "    return jnp.mean(-jnp.sum(y * jnp.log(logits), axis=1))\n",
    "\n",
    "# パラメータの更新\n",
    "@jax.jit\n",
    "def update_params(params, grad, lr = 0.01):\n",
    "    params[\"linear1\"][\"W\"] -= lr * grad[\"linear1\"][\"W\"]\n",
    "    params[\"linear2\"][\"W\"] -= lr * grad[\"linear2\"][\"W\"]\n",
    "    params[\"linear1\"][\"b\"] -= lr * grad[\"linear1\"][\"b\"]\n",
    "    params[\"linear2\"][\"b\"] -= lr * grad[\"linear2\"][\"b\"]\n",
    "    return params\n",
    "\n",
    "# 与えられたXとyで勾配を計算&更新\n",
    "@jax.jit\n",
    "def train(params, X, y):\n",
    "    grad = jax.grad(cross_entropy_loss)(params, X, y)\n",
    "    return update_params(params, grad)\n",
    "\n",
    "# バッチ毎に訓練\n",
    "@jax.jit\n",
    "def train_for_each_batch(batch_idx, params):\n",
    "    target_train_indices = jax.lax.dynamic_slice(index, [batch_idx*batch_size], [batch_size])\n",
    "    params = train(params, X_train[target_train_indices], y_train[target_train_indices])\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "492708b6-1836-4c96-a9a3-5dfa58420235",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "# データセットの読み込み\n",
    "########################################\n",
    "\n",
    "iris_dataset = load_iris()\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris_dataset['data'], iris_dataset['target'], test_size=0.25,  random_state=0)\n",
    "X_train, X_test, y_train, y_test = jax.device_put(X_train), jax.device_put(X_test), jax.device_put(y_train), jax.device_put(y_test)\n",
    "y_train = jnp.eye(3)[y_train]\n",
    "y_test = jnp.eye(3)[y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d103478d-1dbd-4c0f-b509-dd1ac7be3b8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "訓練誤差: 1.332 汎化誤差: 1.460 【 Epoch: 0 / 100 】\n",
      "訓練誤差: 1.089 汎化誤差: 1.164 【 Epoch: 1 / 100 】\n",
      "訓練誤差: 0.982 汎化誤差: 1.047 【 Epoch: 2 / 100 】\n",
      "訓練誤差: 0.923 汎化誤差: 0.984 【 Epoch: 3 / 100 】\n",
      "訓練誤差: 0.878 汎化誤差: 0.939 【 Epoch: 4 / 100 】\n",
      "訓練誤差: 0.838 汎化誤差: 0.900 【 Epoch: 5 / 100 】\n",
      "訓練誤差: 0.805 汎化誤差: 0.866 【 Epoch: 6 / 100 】\n",
      "訓練誤差: 0.776 汎化誤差: 0.837 【 Epoch: 7 / 100 】\n",
      "訓練誤差: 0.750 汎化誤差: 0.811 【 Epoch: 8 / 100 】\n",
      "訓練誤差: 0.727 汎化誤差: 0.788 【 Epoch: 9 / 100 】\n",
      "訓練誤差: 0.707 汎化誤差: 0.768 【 Epoch: 10 / 100 】\n",
      "訓練誤差: 0.690 汎化誤差: 0.750 【 Epoch: 11 / 100 】\n",
      "訓練誤差: 0.674 汎化誤差: 0.733 【 Epoch: 12 / 100 】\n",
      "訓練誤差: 0.659 汎化誤差: 0.718 【 Epoch: 13 / 100 】\n",
      "訓練誤差: 0.646 汎化誤差: 0.705 【 Epoch: 14 / 100 】\n",
      "訓練誤差: 0.634 汎化誤差: 0.692 【 Epoch: 15 / 100 】\n",
      "訓練誤差: 0.622 汎化誤差: 0.680 【 Epoch: 16 / 100 】\n",
      "訓練誤差: 0.611 汎化誤差: 0.669 【 Epoch: 17 / 100 】\n",
      "訓練誤差: 0.601 汎化誤差: 0.659 【 Epoch: 18 / 100 】\n",
      "訓練誤差: 0.591 汎化誤差: 0.649 【 Epoch: 19 / 100 】\n",
      "訓練誤差: 0.582 汎化誤差: 0.639 【 Epoch: 20 / 100 】\n",
      "訓練誤差: 0.573 汎化誤差: 0.631 【 Epoch: 21 / 100 】\n",
      "訓練誤差: 0.565 汎化誤差: 0.622 【 Epoch: 22 / 100 】\n",
      "訓練誤差: 0.557 汎化誤差: 0.614 【 Epoch: 23 / 100 】\n",
      "訓練誤差: 0.550 汎化誤差: 0.606 【 Epoch: 24 / 100 】\n",
      "訓練誤差: 0.542 汎化誤差: 0.599 【 Epoch: 25 / 100 】\n",
      "訓練誤差: 0.536 汎化誤差: 0.592 【 Epoch: 26 / 100 】\n",
      "訓練誤差: 0.529 汎化誤差: 0.585 【 Epoch: 27 / 100 】\n",
      "訓練誤差: 0.523 汎化誤差: 0.579 【 Epoch: 28 / 100 】\n",
      "訓練誤差: 0.517 汎化誤差: 0.572 【 Epoch: 29 / 100 】\n",
      "訓練誤差: 0.511 汎化誤差: 0.566 【 Epoch: 30 / 100 】\n",
      "訓練誤差: 0.505 汎化誤差: 0.561 【 Epoch: 31 / 100 】\n",
      "訓練誤差: 0.500 汎化誤差: 0.555 【 Epoch: 32 / 100 】\n",
      "訓練誤差: 0.495 汎化誤差: 0.550 【 Epoch: 33 / 100 】\n",
      "訓練誤差: 0.490 汎化誤差: 0.545 【 Epoch: 34 / 100 】\n",
      "訓練誤差: 0.485 汎化誤差: 0.540 【 Epoch: 35 / 100 】\n",
      "訓練誤差: 0.480 汎化誤差: 0.535 【 Epoch: 36 / 100 】\n",
      "訓練誤差: 0.476 汎化誤差: 0.531 【 Epoch: 37 / 100 】\n",
      "訓練誤差: 0.471 汎化誤差: 0.526 【 Epoch: 38 / 100 】\n",
      "訓練誤差: 0.467 汎化誤差: 0.522 【 Epoch: 39 / 100 】\n",
      "訓練誤差: 0.463 汎化誤差: 0.518 【 Epoch: 40 / 100 】\n",
      "訓練誤差: 0.459 汎化誤差: 0.514 【 Epoch: 41 / 100 】\n",
      "訓練誤差: 0.455 汎化誤差: 0.510 【 Epoch: 42 / 100 】\n",
      "訓練誤差: 0.451 汎化誤差: 0.506 【 Epoch: 43 / 100 】\n",
      "訓練誤差: 0.448 汎化誤差: 0.503 【 Epoch: 44 / 100 】\n",
      "訓練誤差: 0.444 汎化誤差: 0.499 【 Epoch: 45 / 100 】\n",
      "訓練誤差: 0.441 汎化誤差: 0.495 【 Epoch: 46 / 100 】\n",
      "訓練誤差: 0.437 汎化誤差: 0.492 【 Epoch: 47 / 100 】\n",
      "訓練誤差: 0.434 汎化誤差: 0.489 【 Epoch: 48 / 100 】\n",
      "訓練誤差: 0.431 汎化誤差: 0.485 【 Epoch: 49 / 100 】\n",
      "訓練誤差: 0.427 汎化誤差: 0.482 【 Epoch: 50 / 100 】\n",
      "訓練誤差: 0.424 汎化誤差: 0.479 【 Epoch: 51 / 100 】\n",
      "訓練誤差: 0.421 汎化誤差: 0.476 【 Epoch: 52 / 100 】\n",
      "訓練誤差: 0.418 汎化誤差: 0.473 【 Epoch: 53 / 100 】\n",
      "訓練誤差: 0.415 汎化誤差: 0.470 【 Epoch: 54 / 100 】\n",
      "訓練誤差: 0.412 汎化誤差: 0.467 【 Epoch: 55 / 100 】\n",
      "訓練誤差: 0.410 汎化誤差: 0.464 【 Epoch: 56 / 100 】\n",
      "訓練誤差: 0.407 汎化誤差: 0.462 【 Epoch: 57 / 100 】\n",
      "訓練誤差: 0.404 汎化誤差: 0.459 【 Epoch: 58 / 100 】\n",
      "訓練誤差: 0.401 汎化誤差: 0.456 【 Epoch: 59 / 100 】\n",
      "訓練誤差: 0.399 汎化誤差: 0.454 【 Epoch: 60 / 100 】\n",
      "訓練誤差: 0.396 汎化誤差: 0.451 【 Epoch: 61 / 100 】\n",
      "訓練誤差: 0.394 汎化誤差: 0.449 【 Epoch: 62 / 100 】\n",
      "訓練誤差: 0.391 汎化誤差: 0.446 【 Epoch: 63 / 100 】\n",
      "訓練誤差: 0.389 汎化誤差: 0.444 【 Epoch: 64 / 100 】\n",
      "訓練誤差: 0.386 汎化誤差: 0.441 【 Epoch: 65 / 100 】\n",
      "訓練誤差: 0.384 汎化誤差: 0.439 【 Epoch: 66 / 100 】\n",
      "訓練誤差: 0.382 汎化誤差: 0.437 【 Epoch: 67 / 100 】\n",
      "訓練誤差: 0.379 汎化誤差: 0.434 【 Epoch: 68 / 100 】\n",
      "訓練誤差: 0.377 汎化誤差: 0.432 【 Epoch: 69 / 100 】\n",
      "訓練誤差: 0.375 汎化誤差: 0.430 【 Epoch: 70 / 100 】\n",
      "訓練誤差: 0.372 汎化誤差: 0.428 【 Epoch: 71 / 100 】\n",
      "訓練誤差: 0.370 汎化誤差: 0.425 【 Epoch: 72 / 100 】\n",
      "訓練誤差: 0.368 汎化誤差: 0.423 【 Epoch: 73 / 100 】\n",
      "訓練誤差: 0.366 汎化誤差: 0.421 【 Epoch: 74 / 100 】\n",
      "訓練誤差: 0.364 汎化誤差: 0.419 【 Epoch: 75 / 100 】\n",
      "訓練誤差: 0.362 汎化誤差: 0.417 【 Epoch: 76 / 100 】\n",
      "訓練誤差: 0.360 汎化誤差: 0.415 【 Epoch: 77 / 100 】\n",
      "訓練誤差: 0.358 汎化誤差: 0.413 【 Epoch: 78 / 100 】\n",
      "訓練誤差: 0.356 汎化誤差: 0.411 【 Epoch: 79 / 100 】\n",
      "訓練誤差: 0.354 汎化誤差: 0.409 【 Epoch: 80 / 100 】\n",
      "訓練誤差: 0.352 汎化誤差: 0.407 【 Epoch: 81 / 100 】\n",
      "訓練誤差: 0.350 汎化誤差: 0.405 【 Epoch: 82 / 100 】\n",
      "訓練誤差: 0.348 汎化誤差: 0.403 【 Epoch: 83 / 100 】\n",
      "訓練誤差: 0.346 汎化誤差: 0.401 【 Epoch: 84 / 100 】\n",
      "訓練誤差: 0.344 汎化誤差: 0.400 【 Epoch: 85 / 100 】\n",
      "訓練誤差: 0.342 汎化誤差: 0.398 【 Epoch: 86 / 100 】\n",
      "訓練誤差: 0.340 汎化誤差: 0.396 【 Epoch: 87 / 100 】\n",
      "訓練誤差: 0.338 汎化誤差: 0.394 【 Epoch: 88 / 100 】\n",
      "訓練誤差: 0.336 汎化誤差: 0.392 【 Epoch: 89 / 100 】\n",
      "訓練誤差: 0.335 汎化誤差: 0.391 【 Epoch: 90 / 100 】\n",
      "訓練誤差: 0.333 汎化誤差: 0.389 【 Epoch: 91 / 100 】\n",
      "訓練誤差: 0.331 汎化誤差: 0.387 【 Epoch: 92 / 100 】\n",
      "訓練誤差: 0.329 汎化誤差: 0.386 【 Epoch: 93 / 100 】\n",
      "訓練誤差: 0.328 汎化誤差: 0.384 【 Epoch: 94 / 100 】\n",
      "訓練誤差: 0.326 汎化誤差: 0.382 【 Epoch: 95 / 100 】\n",
      "訓練誤差: 0.324 汎化誤差: 0.381 【 Epoch: 96 / 100 】\n",
      "訓練誤差: 0.323 汎化誤差: 0.379 【 Epoch: 97 / 100 】\n",
      "訓練誤差: 0.321 汎化誤差: 0.377 【 Epoch: 98 / 100 】\n",
      "訓練誤差: 0.319 汎化誤差: 0.376 【 Epoch: 99 / 100 】\n"
     ]
    }
   ],
   "source": [
    "########################################\n",
    "# 学習してみる\n",
    "########################################\n",
    "\n",
    "# パラメータの初期化\n",
    "rng = jax.random.PRNGKey(0)\n",
    "rng1, rng2 = jax.random.split(rng)\n",
    "rng1w, rng1b = jax.random.split(rng1)\n",
    "rng2w, rng2b = jax.random.split(rng2)\n",
    "\n",
    "params = {\n",
    "    \"linear1\": {\n",
    "        \"W\": glorot_normal()(rng1w, (4, 100)),\n",
    "        \"b\": normal()(rng1b, (100,))\n",
    "    },\n",
    "    \"linear2\": {\n",
    "        \"W\": glorot_normal()(rng2w, (100, 3)),\n",
    "        \"b\": normal()(rng2b, (3,))\n",
    "    }\n",
    "}\n",
    "\n",
    "# バッチサイズ\n",
    "batch_size = 50\n",
    "# エポック数\n",
    "epoch_nums = 100\n",
    "\n",
    "# 訓練を回す\n",
    "for epoch_id in range(epoch_nums):\n",
    "\n",
    "    key = jax.random.PRNGKey(epoch_id+1)\n",
    "    \n",
    "    # 訓練データのインデックスをシャッフル\n",
    "    index = jax.random.permutation(key, X_train.shape[0])\n",
    "    # バッチ数\n",
    "    batch_length = jnp.ceil(X_train.shape[0] / batch_size)\n",
    "\n",
    "    # バッチ毎にパラメータを更新していく\n",
    "    params = jax.lax.fori_loop(0, int(batch_length), train_for_each_batch, params)\n",
    "\n",
    "    # 誤差の確認\n",
    "    print(\n",
    "        \"訓練誤差:\",\n",
    "        '{:.3f}'.format(cross_entropy_loss(params, X_train, y_train)),\n",
    "        \"汎化誤差:\",\n",
    "        '{:.3f}'.format(cross_entropy_loss(params, X_test, y_test)),\n",
    "        f\"【 Epoch: {epoch_id} / {epoch_nums} 】\"\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
